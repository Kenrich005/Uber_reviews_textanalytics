{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Understanding the Business Problem\n",
    "Uber Inc in the US wants to know:\n",
    "\n",
    "- the major complaints premium users have about their cab services,\n",
    "- how these impact service ratings.\n",
    "\n",
    "We as (technical) consultants to Uber. have to:  \n",
    "- [a] analyze text reviews of Uber cabs’ US services,  \n",
    "- [b] relate whether and which different features of these reviews impact overall ratings  \n",
    "- [c] pinpoint possible areas of improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pre-processing: \n",
    "- Examine the dataset. \n",
    "- ID the columns of interest. \n",
    "- Drop special characters, html junk etc. \n",
    "- Perform any other preprocessing and text-cleaning activity you think fits this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author_URL</th>\n",
       "      <th>App_Version</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#NEVERUBER</td>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id663331949</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>29-12-2020 01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$$Heaven</td>\n",
       "      <td>Free offer</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id810421958</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>2</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>01-01-2021 23:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.Disappointed....</td>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id49598333</td>\n",
       "      <td>3.439.10000</td>\n",
       "      <td>2</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>15-01-2021 23:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.i. andrea</td>\n",
       "      <td>bad</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id689880334</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>08-12-2020 01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-:deka:-</td>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id124963835</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>15-12-2020 04:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Author_Name                           Title  \\\n",
       "0         #NEVERUBER        Dishonest and Disgusting   \n",
       "1           $$Heaven                      Free offer   \n",
       "2  .Disappointed....                      Inaccurate   \n",
       "3         .i. andrea                             bad   \n",
       "4           -:deka:-  Double charged me for an order   \n",
       "\n",
       "                                        Author_URL  App_Version  Rating  \\\n",
       "0  https://itunes.apple.com/us/reviews/id663331949  3.434.10005       1   \n",
       "1  https://itunes.apple.com/us/reviews/id810421958  3.434.10005       2   \n",
       "2   https://itunes.apple.com/us/reviews/id49598333  3.439.10000       2   \n",
       "3  https://itunes.apple.com/us/reviews/id689880334  3.434.10005       1   \n",
       "4  https://itunes.apple.com/us/reviews/id124963835  3.434.10005       1   \n",
       "\n",
       "                                              Review              Date  \n",
       "0  For half an hour, we tried EVERY UBER SERVICE ...  29-12-2020 01:14  \n",
       "1  If I’m not eligible for the offer Stop floodin...  01-01-2021 23:17  \n",
       "2  Consistently inaccurate Uber Eats ETA and the ...  15-01-2021 23:38  \n",
       "3  i had my rides canceled back to back. they the...  08-12-2020 01:01  \n",
       "4  Two of the same orders was added by accident. ...  15-12-2020 04:02  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Kenrich005/Uber_reviews_textanalytics/main/uber_reviews_itune.csv\",\n",
    "                 encoding='cp1252')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of interest:  \n",
    "1. Title - Brief summary about the review\n",
    "2. Rating - Label for supervised learning\n",
    "3. Review - To extract the sentiment of the complaint\n",
    "4. Date - Extracting weekday or weekend may give better insight on nature of review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>1</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>29-12-2020 01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free offer</td>\n",
       "      <td>2</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>01-01-2021 23:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>2</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>15-01-2021 23:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>1</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>08-12-2020 01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>1</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>15-12-2020 04:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating  \\\n",
       "0        Dishonest and Disgusting       1   \n",
       "1                      Free offer       2   \n",
       "2                      Inaccurate       2   \n",
       "3                             bad       1   \n",
       "4  Double charged me for an order       1   \n",
       "\n",
       "                                              Review              Date  \n",
       "0  For half an hour, we tried EVERY UBER SERVICE ...  29-12-2020 01:14  \n",
       "1  If I’m not eligible for the offer Stop floodin...  01-01-2021 23:17  \n",
       "2  Consistently inaccurate Uber Eats ETA and the ...  15-01-2021 23:38  \n",
       "3  i had my rides canceled back to back. they the...  08-12-2020 01:01  \n",
       "4  Two of the same orders was added by accident. ...  15-12-2020 04:02  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Author_Name','Author_URL','App_Version'],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>CLDR Short Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;U+0001F600&gt;</td>\n",
       "      <td>grinning face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;U+0001F603&gt;</td>\n",
       "      <td>grinning face with big eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;U+0001F604&gt;</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;U+0001F601&gt;</td>\n",
       "      <td>beaming face with smiling eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;U+0001F606&gt;</td>\n",
       "      <td>grinning squinting face</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Code                  CLDR Short Name\n",
       "0  <U+0001F600>                    grinning face\n",
       "1  <U+0001F603>      grinning face with big eyes\n",
       "2  <U+0001F604>  grinning face with smiling eyes\n",
       "3  <U+0001F601>   beaming face with smiling eyes\n",
       "4  <U+0001F606>          grinning squinting face"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing emoticon with its respective meaning\n",
    "df_emojis = pd.read_csv(\"https://raw.githubusercontent.com/Kenrich005/Uber_reviews_textanalytics/main/emoji_description.csv\")\n",
    "df_emojis['Code'] = df_emojis['Code'].str.replace('+','+000')\n",
    "df_emojis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing emoticon with its respective meaning\n",
    "to_replace = df_emojis.Code.tolist()\n",
    "replace_with = df_emojis['CLDR Short Name'].tolist()\n",
    "\n",
    "# using zip() to convert lists to dictionary\n",
    "res = dict(zip(to_replace, replace_with))\n",
    "\n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text + \". \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If I’m not eligible for the offer Stop flooding my email with this false information pouting facepouting facepouting face. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Review = df1.Review.apply(lambda text: replace_all(text, res))\n",
    "df1.Review[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Review = df1.Review.str.split('<').str[0]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If I’m not eligible for the offer Stop flooding my email with this false information pouting facepouting facepouting face. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Review[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Review'].replace('', np.nan, inplace=True)\n",
    "df1.dropna(subset=['Review'], inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# define unit func to process one doc\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "def vader_unit_func(doc0,column_name):\n",
    "    sents_list0 = sent_tokenize(doc0)\n",
    "    vs_doc0 = []\n",
    "    sent_ind = []\n",
    "    for i in range(len(sents_list0)):\n",
    "        vs_sent0 = analyzer.polarity_scores(sents_list0[i])\n",
    "        vs_doc0.append(vs_sent0)\n",
    "        sent_ind.append(i)\n",
    "        \n",
    "    # obtain output as DF    \n",
    "    doc0_df = pd.DataFrame(vs_doc0)\n",
    "    doc0_df.columns = [x+column_name for x in doc0_df.columns]\n",
    "    doc0_df.insert(0, 'sent_index', sent_ind)  # insert sent index\n",
    "    doc0_df.insert(doc0_df.shape[1], 'sentence', sents_list0)\n",
    "    return(doc0_df)\n",
    "\n",
    "# define wrapper func\n",
    "def vader_wrap_func(corpus0,column_name):\n",
    "    \n",
    "    # use ifinstance() to check & convert input to DF\n",
    "    if isinstance(corpus0, list):\n",
    "        corpus0 = pd.DataFrame({'text':corpus0})\n",
    "    \n",
    "    # define empty DF to concat unit func output to\n",
    "    vs_df = pd.DataFrame()    \n",
    "    \n",
    "    # apply unit-func to each doc & loop over all docs\n",
    "    for i1 in range(len(corpus0)):\n",
    "        doc0 = str(corpus0.iloc[i1])\n",
    "        vs_doc_df = vader_unit_func(doc0,column_name)  # applying unit-func\n",
    "        vs_doc_df.insert(0, 'doc_index', i1)  # inserting doc index\n",
    "        vs_df = pd.concat([vs_df, vs_doc_df], axis=0)\n",
    "        \n",
    "    return(vs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>neg_review</th>\n",
       "      <th>neu_review</th>\n",
       "      <th>pos_review</th>\n",
       "      <th>compound_review</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>neg_title</th>\n",
       "      <th>neu_title</th>\n",
       "      <th>pos_title</th>\n",
       "      <th>compound_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>29-12-2020 01:14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.876</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free offer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>01-01-2021 23:17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>15-01-2021 23:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>08-12-2020 01:01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.167</td>\n",
       "      <td>3.592</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.1617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>15-12-2020 04:02</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>5.614</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.4906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating  \\\n",
       "0        Dishonest and Disgusting     1.0   \n",
       "1                      Free offer     2.0   \n",
       "2                      Inaccurate     2.0   \n",
       "3                             bad     1.0   \n",
       "4  Double charged me for an order     1.0   \n",
       "\n",
       "                                              Review              Date  \\\n",
       "0  For half an hour, we tried EVERY UBER SERVICE ...  29-12-2020 01:14   \n",
       "1  If I’m not eligible for the offer Stop floodin...  01-01-2021 23:17   \n",
       "2  Consistently inaccurate Uber Eats ETA and the ...  15-01-2021 23:38   \n",
       "3  i had my rides canceled back to back. they the...  08-12-2020 01:01   \n",
       "4  Two of the same orders was added by accident. ...  15-12-2020 04:02   \n",
       "\n",
       "   sent_index  neg_review  neu_review  pos_review  compound_review  \\\n",
       "0         3.0       0.000       2.876       0.124           0.1406   \n",
       "1         0.0       0.109       0.891       0.000          -0.2960   \n",
       "2         0.0       0.179       0.821       0.000          -0.3400   \n",
       "3        10.0       1.167       3.592       0.241          -0.1617   \n",
       "4        21.0       0.908       5.614       0.478          -0.4906   \n",
       "\n",
       "   sent_index  neg_title  neu_title  pos_title  compound_title  \n",
       "0         0.0      0.877      0.123      0.000         -0.7964  \n",
       "1         0.0      0.000      0.233      0.767          0.5106  \n",
       "2         0.0      0.000      1.000      0.000          0.0000  \n",
       "3         0.0      1.000      0.000      0.000         -0.5423  \n",
       "4         0.0      0.265      0.735      0.000         -0.2023  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test-drive wrapper func\n",
    "review_sentiment = vader_wrap_func(df1.Review,'_review').groupby('doc_index').sum()\n",
    "title_sentiment = vader_wrap_func(df1.Title,'_title').groupby('doc_index').sum()\n",
    "df1 = pd.concat([df1,review_sentiment,title_sentiment],axis=1)\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-12-29 01:14:00\n",
       "1   2021-01-01 23:17:00\n",
       "2   2021-01-15 23:38:00\n",
       "3   2020-12-08 01:01:00\n",
       "4   2020-12-15 04:02:00\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Date into datetime format\n",
    "df1['Date'] =  pd.to_datetime(df1['Date'], format='%d-%m-%Y %H:%M')\n",
    "df1.Date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>neg_review</th>\n",
       "      <th>neu_review</th>\n",
       "      <th>pos_review</th>\n",
       "      <th>compound_review</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>...</th>\n",
       "      <th>neu_title</th>\n",
       "      <th>pos_title</th>\n",
       "      <th>compound_title</th>\n",
       "      <th>Isweekend</th>\n",
       "      <th>Late_night</th>\n",
       "      <th>Early_mrng</th>\n",
       "      <th>Morning</th>\n",
       "      <th>Noon</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>2020-12-29 01:14:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.876</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free offer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>2021-01-01 23:17:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>2021-01-15 23:38:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>2020-12-08 01:01:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.167</td>\n",
       "      <td>3.592</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.1617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>2020-12-15 04:02:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>5.614</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.4906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating  \\\n",
       "0        Dishonest and Disgusting     1.0   \n",
       "1                      Free offer     2.0   \n",
       "2                      Inaccurate     2.0   \n",
       "3                             bad     1.0   \n",
       "4  Double charged me for an order     1.0   \n",
       "\n",
       "                                              Review                Date  \\\n",
       "0  For half an hour, we tried EVERY UBER SERVICE ... 2020-12-29 01:14:00   \n",
       "1  If I’m not eligible for the offer Stop floodin... 2021-01-01 23:17:00   \n",
       "2  Consistently inaccurate Uber Eats ETA and the ... 2021-01-15 23:38:00   \n",
       "3  i had my rides canceled back to back. they the... 2020-12-08 01:01:00   \n",
       "4  Two of the same orders was added by accident. ... 2020-12-15 04:02:00   \n",
       "\n",
       "   sent_index  neg_review  neu_review  pos_review  compound_review  \\\n",
       "0         3.0       0.000       2.876       0.124           0.1406   \n",
       "1         0.0       0.109       0.891       0.000          -0.2960   \n",
       "2         0.0       0.179       0.821       0.000          -0.3400   \n",
       "3        10.0       1.167       3.592       0.241          -0.1617   \n",
       "4        21.0       0.908       5.614       0.478          -0.4906   \n",
       "\n",
       "   sent_index  ...  neu_title  pos_title  compound_title  Isweekend  \\\n",
       "0         0.0  ...      0.123      0.000         -0.7964          0   \n",
       "1         0.0  ...      0.233      0.767          0.5106          0   \n",
       "2         0.0  ...      1.000      0.000          0.0000          0   \n",
       "3         0.0  ...      0.000      0.000         -0.5423          0   \n",
       "4         0.0  ...      0.735      0.000         -0.2023          0   \n",
       "\n",
       "   Late_night  Early_mrng  Morning  Noon  Eve  Night  \n",
       "0           1           0        0     0    0      0  \n",
       "1           0           0        0     0    0      1  \n",
       "2           0           0        0     0    0      1  \n",
       "3           1           0        0     0    0      0  \n",
       "4           0           1        0     0    0      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Isweekend'] = np.where(df1.Date.dt.dayofweek>4,1,0)\n",
    "df1['Late_night'] = np.where(df1.Date.dt.hour<4,1,0)\n",
    "df1['Early_mrng'] = np.where(df1.Date.dt.hour.between(4,8),1,0)\n",
    "df1['Morning'] = np.where(df1.Date.dt.hour.between(8,12),1,0)\n",
    "df1['Noon'] = np.where(df1.Date.dt.hour.between(12,16),1,0)\n",
    "df1['Eve'] = np.where(df1.Date.dt.hour.between(16,20),1,0)\n",
    "df1['Night'] = np.where(df1.Date.dt.hour>20,1,0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>neg_review</th>\n",
       "      <th>neu_review</th>\n",
       "      <th>pos_review</th>\n",
       "      <th>compound_review</th>\n",
       "      <th>neg_title</th>\n",
       "      <th>neu_title</th>\n",
       "      <th>pos_title</th>\n",
       "      <th>compound_title</th>\n",
       "      <th>Isweekend</th>\n",
       "      <th>Late_night</th>\n",
       "      <th>Early_mrng</th>\n",
       "      <th>Morning</th>\n",
       "      <th>Noon</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.876</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.167</td>\n",
       "      <td>3.592</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.1617</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>5.614</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.4906</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  neg_review  neu_review  pos_review  compound_review  neg_title  \\\n",
       "0     1.0       0.000       2.876       0.124           0.1406      0.877   \n",
       "1     2.0       0.109       0.891       0.000          -0.2960      0.000   \n",
       "2     2.0       0.179       0.821       0.000          -0.3400      0.000   \n",
       "3     1.0       1.167       3.592       0.241          -0.1617      1.000   \n",
       "4     1.0       0.908       5.614       0.478          -0.4906      0.265   \n",
       "\n",
       "   neu_title  pos_title  compound_title  Isweekend  Late_night  Early_mrng  \\\n",
       "0      0.123      0.000         -0.7964          0           1           0   \n",
       "1      0.233      0.767          0.5106          0           0           0   \n",
       "2      1.000      0.000          0.0000          0           0           0   \n",
       "3      0.000      0.000         -0.5423          0           1           0   \n",
       "4      0.735      0.000         -0.2023          0           0           1   \n",
       "\n",
       "   Morning  Noon  Eve  Night  \n",
       "0        0     0    0      0  \n",
       "1        0     0    0      1  \n",
       "2        0     0    0      1  \n",
       "3        0     0    0      0  \n",
       "4        0     0    0      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.drop(['sent_index','Title','Review','Date'],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing null values\n",
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((488,), (488, 15))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1.Rating\n",
    "X = df1.drop('Rating', axis=1)\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg_review         0\n",
       "neu_review         0\n",
       "pos_review         0\n",
       "compound_review    0\n",
       "neg_title          0\n",
       "neu_title          0\n",
       "pos_title          0\n",
       "compound_title     0\n",
       "Isweekend          0\n",
       "Late_night         0\n",
       "Early_mrng         0\n",
       "Morning            0\n",
       "Noon               0\n",
       "Eve                0\n",
       "Night              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.9228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Jul 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.539</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:55:17</td>     <th>  Log-Likelihood:    </th> <td> -690.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   488</td>      <th>  AIC:               </th> <td>   1413.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   472</td>      <th>  BIC:               </th> <td>   1480.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>    1.5688</td> <td>    0.312</td> <td>    5.027</td> <td> 0.000</td> <td>    0.956</td> <td>    2.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neg_review</th>      <td>   -0.0306</td> <td>    0.170</td> <td>   -0.180</td> <td> 0.857</td> <td>   -0.364</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neu_review</th>      <td>   -0.0173</td> <td>    0.020</td> <td>   -0.855</td> <td> 0.393</td> <td>   -0.057</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_review</th>      <td>    0.1157</td> <td>    0.204</td> <td>    0.567</td> <td> 0.571</td> <td>   -0.285</td> <td>    0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>compound_review</th> <td>    0.0072</td> <td>    0.103</td> <td>    0.070</td> <td> 0.944</td> <td>   -0.195</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neg_title</th>       <td>    0.0261</td> <td>    0.387</td> <td>    0.067</td> <td> 0.946</td> <td>   -0.735</td> <td>    0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neu_title</th>       <td>   -0.0237</td> <td>    0.232</td> <td>   -0.102</td> <td> 0.918</td> <td>   -0.479</td> <td>    0.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_title</th>       <td>    0.0223</td> <td>    0.413</td> <td>    0.054</td> <td> 0.957</td> <td>   -0.790</td> <td>    0.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>compound_title</th>  <td>    0.2879</td> <td>    0.365</td> <td>    0.790</td> <td> 0.430</td> <td>   -0.428</td> <td>    1.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Isweekend</th>       <td>   -0.1134</td> <td>    0.102</td> <td>   -1.111</td> <td> 0.267</td> <td>   -0.314</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Late_night</th>      <td>    0.1776</td> <td>    0.238</td> <td>    0.745</td> <td> 0.457</td> <td>   -0.291</td> <td>    0.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Early_mrng</th>      <td>   -0.1627</td> <td>    0.230</td> <td>   -0.707</td> <td> 0.480</td> <td>   -0.615</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Morning</th>         <td>   -0.1279</td> <td>    0.199</td> <td>   -0.643</td> <td> 0.520</td> <td>   -0.518</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Noon</th>            <td>   -0.0107</td> <td>    0.165</td> <td>   -0.065</td> <td> 0.948</td> <td>   -0.334</td> <td>    0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Eve</th>             <td>    0.1066</td> <td>    0.209</td> <td>    0.509</td> <td> 0.611</td> <td>   -0.305</td> <td>    0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Night</th>           <td>    0.1382</td> <td>    0.237</td> <td>    0.582</td> <td> 0.561</td> <td>   -0.328</td> <td>    0.605</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>205.684</td> <th>  Durbin-Watson:     </th> <td>   2.117</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 631.298</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.077</td>  <th>  Prob(JB):          </th> <td>8.23e-138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.713</td>  <th>  Cond. No.          </th> <td>    52.5</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.028\n",
       "Model:                            OLS   Adj. R-squared:                 -0.002\n",
       "Method:                 Least Squares   F-statistic:                    0.9228\n",
       "Date:                Mon, 11 Jul 2022   Prob (F-statistic):              0.539\n",
       "Time:                        23:55:17   Log-Likelihood:                -690.34\n",
       "No. Observations:                 488   AIC:                             1413.\n",
       "Df Residuals:                     472   BIC:                             1480.\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const               1.5688      0.312      5.027      0.000       0.956       2.182\n",
       "neg_review         -0.0306      0.170     -0.180      0.857      -0.364       0.303\n",
       "neu_review         -0.0173      0.020     -0.855      0.393      -0.057       0.022\n",
       "pos_review          0.1157      0.204      0.567      0.571      -0.285       0.516\n",
       "compound_review     0.0072      0.103      0.070      0.944      -0.195       0.209\n",
       "neg_title           0.0261      0.387      0.067      0.946      -0.735       0.787\n",
       "neu_title          -0.0237      0.232     -0.102      0.918      -0.479       0.431\n",
       "pos_title           0.0223      0.413      0.054      0.957      -0.790       0.834\n",
       "compound_title      0.2879      0.365      0.790      0.430      -0.428       1.004\n",
       "Isweekend          -0.1134      0.102     -1.111      0.267      -0.314       0.087\n",
       "Late_night          0.1776      0.238      0.745      0.457      -0.291       0.646\n",
       "Early_mrng         -0.1627      0.230     -0.707      0.480      -0.615       0.289\n",
       "Morning            -0.1279      0.199     -0.643      0.520      -0.518       0.263\n",
       "Noon               -0.0107      0.165     -0.065      0.948      -0.334       0.313\n",
       "Eve                 0.1066      0.209      0.509      0.611      -0.305       0.518\n",
       "Night               0.1382      0.237      0.582      0.561      -0.328       0.605\n",
       "==============================================================================\n",
       "Omnibus:                      205.684   Durbin-Watson:                   2.117\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              631.298\n",
       "Skew:                           2.077   Prob(JB):                    8.23e-138\n",
       "Kurtosis:                       6.713   Cond. No.                         52.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_review</th>\n",
       "      <th>neu_review</th>\n",
       "      <th>pos_review</th>\n",
       "      <th>compound_review</th>\n",
       "      <th>neg_title</th>\n",
       "      <th>neu_title</th>\n",
       "      <th>pos_title</th>\n",
       "      <th>compound_title</th>\n",
       "      <th>Isweekend</th>\n",
       "      <th>Late_night</th>\n",
       "      <th>Early_mrng</th>\n",
       "      <th>Morning</th>\n",
       "      <th>Noon</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.876</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.167</td>\n",
       "      <td>3.592</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.1617</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.908</td>\n",
       "      <td>5.614</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.4906</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neg_review  neu_review  pos_review  compound_review  neg_title  neu_title  \\\n",
       "0       0.000       2.876       0.124           0.1406      0.877      0.123   \n",
       "1       0.109       0.891       0.000          -0.2960      0.000      0.233   \n",
       "2       0.179       0.821       0.000          -0.3400      0.000      1.000   \n",
       "3       1.167       3.592       0.241          -0.1617      1.000      0.000   \n",
       "4       0.908       5.614       0.478          -0.4906      0.265      0.735   \n",
       "\n",
       "   pos_title  compound_title  Isweekend  Late_night  Early_mrng  Morning  \\\n",
       "0      0.000         -0.7964          0           1           0        0   \n",
       "1      0.767          0.5106          0           0           0        0   \n",
       "2      0.000          0.0000          0           0           0        0   \n",
       "3      0.000         -0.5423          0           1           0        0   \n",
       "4      0.000         -0.2023          0           0           1        0   \n",
       "\n",
       "   Noon  Eve  Night  \n",
       "0     0    0      0  \n",
       "1     0    0      1  \n",
       "2     0    0      1  \n",
       "3     0    0      0  \n",
       "4     0    0      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop('const',axis=1,inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((341, 15), (147, 15), (341,), (147,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "   \n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif['VIF'].sort_values()\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg_review</td>\n",
       "      <td>4.788130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neu_review</td>\n",
       "      <td>3.537659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos_review</td>\n",
       "      <td>4.677592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compound_review</td>\n",
       "      <td>3.463821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg_title</td>\n",
       "      <td>8.894055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neu_title</td>\n",
       "      <td>8.529873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pos_title</td>\n",
       "      <td>3.214399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>compound_title</td>\n",
       "      <td>7.526287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Isweekend</td>\n",
       "      <td>1.469303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Late_night</td>\n",
       "      <td>3.464946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Early_mrng</td>\n",
       "      <td>2.668715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Morning</td>\n",
       "      <td>1.951910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Noon</td>\n",
       "      <td>1.865737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Eve</td>\n",
       "      <td>4.231675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Night</td>\n",
       "      <td>3.612687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variables       VIF\n",
       "0        neg_review  4.788130\n",
       "1        neu_review  3.537659\n",
       "2        pos_review  4.677592\n",
       "3   compound_review  3.463821\n",
       "4         neg_title  8.894055\n",
       "5         neu_title  8.529873\n",
       "6         pos_title  3.214399\n",
       "7    compound_title  7.526287\n",
       "8         Isweekend  1.469303\n",
       "9        Late_night  3.464946\n",
       "10       Early_mrng  2.668715\n",
       "11          Morning  1.951910\n",
       "12             Noon  1.865737\n",
       "13              Eve  4.231675\n",
       "14            Night  3.612687"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_vif(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, a VIF above 4 or tolerance below 0.25 indicates that multicollinearity might exist, and further investigation is required.   \n",
    "When VIF is higher than 10 or tolerance is lower than 0.1, there is significant multicollinearity that needs to be corrected.  \n",
    "  \n",
    "Since all the above variables have VIF below 4 and above 0.25, we can be assured that there is no multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will save the model performance metrics in a DataFrame\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "Model = []\n",
    "RMSE = []\n",
    "R_sq = []\n",
    "cv = KFold(5)\n",
    "\n",
    "#Creating a Function to append the cross validation scores of the algorithms\n",
    "def input_scores(name, model, x, y):\n",
    "    Model.append(name)\n",
    "    RMSE.append(np.sqrt((-1) * cross_val_score(model, x, y, cv=cv, scoring='neg_mean_squared_error').mean()))\n",
    "    R_sq.append(cross_val_score(model, x, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor)\n",
    "\n",
    "names = ['Linear Regression', 'Ridge Regression', 'Lasso Regression',\n",
    "         'K Neighbors Regressor', 'Decision Tree Regressor', \n",
    "         'Random Forest Regressor', 'Gradient Boosting Regressor',\n",
    "         'Adaboost Regressor','XGBRegressor']\n",
    "\n",
    "models = [LinearRegression(), Ridge(), Lasso(),\n",
    "          KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(), GradientBoostingRegressor(), \n",
    "          AdaBoostRegressor(),XGBRegressor()]\n",
    "\n",
    "#Running all algorithms\n",
    "for name, model in zip(names, models):\n",
    "    input_scores(name, model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/swatisinghalmav/best-of-8-regression-models-to-predict-strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWING ARE THE TRAINING SCORES: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.059554</td>\n",
       "      <td>-0.110657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>1.052507</td>\n",
       "      <td>-0.093496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>1.013998</td>\n",
       "      <td>-0.009029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K Neighbors Regressor</td>\n",
       "      <td>1.147376</td>\n",
       "      <td>-0.317304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>1.405941</td>\n",
       "      <td>-1.117294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>1.111993</td>\n",
       "      <td>-0.261260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>1.167720</td>\n",
       "      <td>-0.376211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost Regressor</td>\n",
       "      <td>1.166531</td>\n",
       "      <td>-0.357489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>1.207863</td>\n",
       "      <td>-0.463601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model      RMSE  R Squared\n",
       "0            Linear Regression  1.059554  -0.110657\n",
       "1             Ridge Regression  1.052507  -0.093496\n",
       "2             Lasso Regression  1.013998  -0.009029\n",
       "3        K Neighbors Regressor  1.147376  -0.317304\n",
       "4      Decision Tree Regressor  1.405941  -1.117294\n",
       "5      Random Forest Regressor  1.111993  -0.261260\n",
       "6  Gradient Boosting Regressor  1.167720  -0.376211\n",
       "7           Adaboost Regressor  1.166531  -0.357489\n",
       "8                 XGBRegressor  1.207863  -0.463601"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.DataFrame({'Model': Model,'RMSE': RMSE,'R Squared': R_sq})\n",
    "print(\"FOLLOWING ARE THE TRAINING SCORES: \")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "1. Convert non-English reviews to English or use non-english dictionary - ## need to add to current code\n",
    "2. Scale the emoticons replacement - ## validation pending\n",
    "3. Make sentiment analysis of Title - ## Done\n",
    "4. From Date, extract weekend, weekday, morning, afternoon, evening, night - ## Done\n",
    "5. Make preliminary regression model with y variable as Ratings - ## Done\n",
    "6. ?Use OLS - ## Done\n",
    "7. Feature Engineering - columns on specific word count\n",
    "8. Shiny App\n",
    "9. Add PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
