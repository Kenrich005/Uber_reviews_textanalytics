{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Understanding the Business Problem\n",
    "Uber Inc in the US wants to know:\n",
    "\n",
    "- the major complaints premium users have about their cab services,\n",
    "- how these impact service ratings.\n",
    "\n",
    "We as (technical) consultants to Uber. have to:  \n",
    "- [a] analyze text reviews of Uber cabs’ US services,  \n",
    "- [b] relate whether and which different features of these reviews impact overall ratings  \n",
    "- [c] pinpoint possible areas of improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pre-processing: \n",
    "- Examine the dataset. \n",
    "- ID the columns of interest. \n",
    "- Drop special characters, html junk etc. \n",
    "- Perform any other preprocessing and text-cleaning activity you think fits this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author_URL</th>\n",
       "      <th>App_Version</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#NEVERUBER</td>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id663331949</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>29-12-2020 01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$$Heaven</td>\n",
       "      <td>Free offer</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id810421958</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>2</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>01-01-2021 23:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.Disappointed....</td>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id49598333</td>\n",
       "      <td>3.439.10000</td>\n",
       "      <td>2</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>15-01-2021 23:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.i. andrea</td>\n",
       "      <td>bad</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id689880334</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>08-12-2020 01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-:deka:-</td>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id124963835</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>15-12-2020 04:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Author_Name                           Title  \\\n",
       "0         #NEVERUBER        Dishonest and Disgusting   \n",
       "1           $$Heaven                      Free offer   \n",
       "2  .Disappointed....                      Inaccurate   \n",
       "3         .i. andrea                             bad   \n",
       "4           -:deka:-  Double charged me for an order   \n",
       "\n",
       "                                        Author_URL  App_Version  Rating  \\\n",
       "0  https://itunes.apple.com/us/reviews/id663331949  3.434.10005       1   \n",
       "1  https://itunes.apple.com/us/reviews/id810421958  3.434.10005       2   \n",
       "2   https://itunes.apple.com/us/reviews/id49598333  3.439.10000       2   \n",
       "3  https://itunes.apple.com/us/reviews/id689880334  3.434.10005       1   \n",
       "4  https://itunes.apple.com/us/reviews/id124963835  3.434.10005       1   \n",
       "\n",
       "                                              Review              Date  \n",
       "0  For half an hour, we tried EVERY UBER SERVICE ...  29-12-2020 01:14  \n",
       "1  If I’m not eligible for the offer Stop floodin...  01-01-2021 23:17  \n",
       "2  Consistently inaccurate Uber Eats ETA and the ...  15-01-2021 23:38  \n",
       "3  i had my rides canceled back to back. they the...  08-12-2020 01:01  \n",
       "4  Two of the same orders was added by accident. ...  15-12-2020 04:02  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"G:\\ISB AMPBA\\9. Text Analytics\\Assignment\\uber_reviews_itune.csv\",\n",
    "                 encoding='cp1252')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of interest:  \n",
    "1. Title - Brief summary about the review\n",
    "2. Rating - Label for supervised learning\n",
    "3. Review - To extract the sentiment of the complaint\n",
    "4. Date - Extracting weekday or weekend may give better insight on nature of review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>1</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>29-12-2020 01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free offer</td>\n",
       "      <td>2</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>01-01-2021 23:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>2</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>15-01-2021 23:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>1</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>08-12-2020 01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>1</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>15-12-2020 04:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating  \\\n",
       "0        Dishonest and Disgusting       1   \n",
       "1                      Free offer       2   \n",
       "2                      Inaccurate       2   \n",
       "3                             bad       1   \n",
       "4  Double charged me for an order       1   \n",
       "\n",
       "                                              Review              Date  \n",
       "0  For half an hour, we tried EVERY UBER SERVICE ...  29-12-2020 01:14  \n",
       "1  If I’m not eligible for the offer Stop floodin...  01-01-2021 23:17  \n",
       "2  Consistently inaccurate Uber Eats ETA and the ...  15-01-2021 23:38  \n",
       "3  i had my rides canceled back to back. they the...  08-12-2020 01:01  \n",
       "4  Two of the same orders was added by accident. ...  15-12-2020 04:02  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Author_Name','Author_URL','App_Version'],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing emoticon with its respective meaning\n",
    "to_replace=['<U+0001F621>','<U+0001F615>','<U+0001F44E>']\n",
    "replace_with=['pouting face','confused face','thumbs down']\n",
    "df1.Review=df1.Review.replace(to_replace, replace_with, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Review = df1.Review.str.split('<').str[0]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop empty rows or docs\n",
    "df1.Review[149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Review'].replace('', np.nan, inplace=True)\n",
    "df1.dropna(subset=['Review'], inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Stemming\n",
    "\n",
    "Below we import NLTK's sentence and word tokenizer, and stemmer. Note the use of list comprehension to bundle both into one  line of efficient code.\n",
    "\n",
    "Note also the use of regex from *re* to detect and drop any non alphabetic characters from the corpus.\n",
    "\n",
    "Find below two straightforward user defined funcs to tokenize (and stem).\n",
    "\n",
    "We will apply these funcs on each doc in the corpus subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.962, 'pos': 0.038, 'compound': 0.1406}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# see what kinda output VADER yields on 1 doc first\n",
    "vs0 = analyzer.polarity_scores(df1.Review.iloc[0]); \n",
    "vs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.962, 'pos': 0.038, 'compound': 0.1406}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = df1.Review.iloc[0]\n",
    "analyzer.polarity_scores(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu  pos  compound\n",
       "0  0.136  0.864  0.0    -0.296\n",
       "1  0.179  0.821  0.0    -0.340"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list = []\n",
    "sent1 = analyzer.polarity_scores(df1.Review[1])\n",
    "sent_list.append(sent1)\n",
    "sent1 = analyzer.polarity_scores(df1.Review[2])\n",
    "sent_list.append(sent1)\n",
    "pd.DataFrame(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-f42ad3eff520>\u001b[0m in \u001b[0;36mvader_unit_func\u001b[1;34m(doc0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define unit func to process one doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvader_unit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msents_list0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mvs_doc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msent_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sent_tokenize' is not defined"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'doc0_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f42ad3eff520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# test-run unit func on nokia[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'doc0_df = vader_unit_func(df1.Review.iloc[0])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mdoc0_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'doc0_df' is not defined"
     ]
    }
   ],
   "source": [
    "# define unit func to process one doc\n",
    "def vader_unit_func(doc0):\n",
    "    sents_list0 = sent_tokenize(doc0)\n",
    "    vs_doc0 = []\n",
    "    sent_ind = []\n",
    "    for sent in sents_list0:\n",
    "        vs_sent0 = analyzer.polarity_scores(sent)\n",
    "        vs_doc0.append(vs_sent0)\n",
    "#         sent_ind.append(i)\n",
    "        \n",
    "    # obtain output as DF    \n",
    "    doc0_df = pd.DataFrame(vs_doc0)\n",
    "#     doc0_df.insert(0, 'sent_index', sent_ind)  # insert sent index\n",
    "    doc0_df.insert(doc0_df.shape[1], 'sentence', sents_list0)\n",
    "    return(doc0_df)\n",
    "\n",
    "# test-run unit func on nokia[0]\n",
    "%time doc0_df = vader_unit_func(df1.Review.iloc[0])\n",
    "doc0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wrapper func\n",
    "def vader_wrap_func(corpus0):\n",
    "    \n",
    "    # use ifinstance() to check & convert input to DF\n",
    "    if isinstance(corpus0, list):\n",
    "        corpus0 = pd.DataFrame({'text':corpus0})\n",
    "    \n",
    "    # define empty DF to concat unit func output to\n",
    "    vs_df = pd.DataFrame(columns=['doc_index', 'sent_index', 'neg', 'neu', 'pos', 'compound', 'sentence'])    \n",
    "    \n",
    "    # apply unit-func to each doc & loop over all docs\n",
    "    for i1 in range(len(corpus0)):\n",
    "        doc0 = str(corpus0.iloc[i1])\n",
    "        vs_doc_df = vader_unit_func(doc0)  # applying unit-func\n",
    "        vs_doc_df.insert(0, 'doc_index', i1)  # inserting doc index\n",
    "        vs_df = pd.concat([vs_df, vs_doc_df], axis=0)\n",
    "        \n",
    "    return(vs_df)\n",
    "\n",
    "# test-drive wrapper func\n",
    "%time nokia_vs_df = vader_wrap_func(df1.Review)    \n",
    "nokia_vs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
