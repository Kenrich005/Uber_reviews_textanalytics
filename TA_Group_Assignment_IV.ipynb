{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Understanding the Business Problem\n",
    "Uber Inc in the US wants to know:\n",
    "\n",
    "- the major complaints premium users have about their cab services,\n",
    "- how these impact service ratings.\n",
    "\n",
    "We as (technical) consultants to Uber. have to:  \n",
    "- [a] analyze text reviews of Uber cabs’ US services,  \n",
    "- [b] relate whether and which different features of these reviews impact overall ratings  \n",
    "- [c] pinpoint possible areas of improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pre-processing: \n",
    "- Examine the dataset. \n",
    "- ID the columns of interest. \n",
    "- Drop special characters, html junk etc. \n",
    "- Perform any other preprocessing and text-cleaning activity you think fits this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author_URL</th>\n",
       "      <th>App_Version</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#NEVERUBER</td>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id663331949</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>29-12-2020 01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$$Heaven</td>\n",
       "      <td>Free offer</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id810421958</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>2</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>01-01-2021 23:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.Disappointed....</td>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id49598333</td>\n",
       "      <td>3.439.10000</td>\n",
       "      <td>2</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>15-01-2021 23:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.i. andrea</td>\n",
       "      <td>bad</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id689880334</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>08-12-2020 01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-:deka:-</td>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>https://itunes.apple.com/us/reviews/id124963835</td>\n",
       "      <td>3.434.10005</td>\n",
       "      <td>1</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>15-12-2020 04:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Author_Name                           Title  \\\n",
       "0         #NEVERUBER        Dishonest and Disgusting   \n",
       "1           $$Heaven                      Free offer   \n",
       "2  .Disappointed....                      Inaccurate   \n",
       "3         .i. andrea                             bad   \n",
       "4           -:deka:-  Double charged me for an order   \n",
       "\n",
       "                                        Author_URL  App_Version  Rating  \\\n",
       "0  https://itunes.apple.com/us/reviews/id663331949  3.434.10005       1   \n",
       "1  https://itunes.apple.com/us/reviews/id810421958  3.434.10005       2   \n",
       "2   https://itunes.apple.com/us/reviews/id49598333  3.439.10000       2   \n",
       "3  https://itunes.apple.com/us/reviews/id689880334  3.434.10005       1   \n",
       "4  https://itunes.apple.com/us/reviews/id124963835  3.434.10005       1   \n",
       "\n",
       "                                              Review              Date  \n",
       "0  For half an hour, we tried EVERY UBER SERVICE ...  29-12-2020 01:14  \n",
       "1  If I’m not eligible for the offer Stop floodin...  01-01-2021 23:17  \n",
       "2  Consistently inaccurate Uber Eats ETA and the ...  15-01-2021 23:38  \n",
       "3  i had my rides canceled back to back. they the...  08-12-2020 01:01  \n",
       "4  Two of the same orders was added by accident. ...  15-12-2020 04:02  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"G:\\ISB AMPBA\\9. Text Analytics\\Assignment\\uber_reviews_itune.csv\",\n",
    "                 encoding='cp1252')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of interest:  \n",
    "1. Title - Brief summary about the review\n",
    "2. Rating - Label for supervised learning\n",
    "3. Review - To extract the sentiment of the complaint\n",
    "4. Date - Extracting weekday or weekend may give better insight on nature of review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>1</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>29-12-2020 01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free offer</td>\n",
       "      <td>2</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>01-01-2021 23:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>2</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>15-01-2021 23:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>1</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>08-12-2020 01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>1</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>15-12-2020 04:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating  \\\n",
       "0        Dishonest and Disgusting       1   \n",
       "1                      Free offer       2   \n",
       "2                      Inaccurate       2   \n",
       "3                             bad       1   \n",
       "4  Double charged me for an order       1   \n",
       "\n",
       "                                              Review              Date  \n",
       "0  For half an hour, we tried EVERY UBER SERVICE ...  29-12-2020 01:14  \n",
       "1  If I’m not eligible for the offer Stop floodin...  01-01-2021 23:17  \n",
       "2  Consistently inaccurate Uber Eats ETA and the ...  15-01-2021 23:38  \n",
       "3  i had my rides canceled back to back. they the...  08-12-2020 01:01  \n",
       "4  Two of the same orders was added by accident. ...  15-12-2020 04:02  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Author_Name','Author_URL','App_Version'],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing emoticon with its respective meaning\n",
    "to_replace=['<U+0001F621>','<U+0001F615>','<U+0001F44E>']\n",
    "replace_with=['pouting face','confused face','thumbs down']\n",
    "df1.Review=df1.Review.replace(to_replace, replace_with, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Review = df1.Review.str.split('<').str[0]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Review'].replace('', np.nan, inplace=True)\n",
    "df1.dropna(subset=['Review'], inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# define unit func to process one doc\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "def vader_unit_func(doc0,column_name):\n",
    "    sents_list0 = sent_tokenize(doc0)\n",
    "    vs_doc0 = []\n",
    "    sent_ind = []\n",
    "    for i in range(len(sents_list0)):\n",
    "        vs_sent0 = analyzer.polarity_scores(sents_list0[i])\n",
    "        vs_doc0.append(vs_sent0)\n",
    "        sent_ind.append(i)\n",
    "        \n",
    "    # obtain output as DF    \n",
    "    doc0_df = pd.DataFrame(vs_doc0)\n",
    "    doc0_df.columns = [x+column_name for x in doc0_df.columns]\n",
    "    doc0_df.insert(0, 'sent_index', sent_ind)  # insert sent index\n",
    "    doc0_df.insert(doc0_df.shape[1], 'sentence', sents_list0)\n",
    "    return(doc0_df)\n",
    "\n",
    "# define wrapper func\n",
    "def vader_wrap_func(corpus0,column_name):\n",
    "    \n",
    "    # use ifinstance() to check & convert input to DF\n",
    "    if isinstance(corpus0, list):\n",
    "        corpus0 = pd.DataFrame({'text':corpus0})\n",
    "    \n",
    "    # define empty DF to concat unit func output to\n",
    "    vs_df = pd.DataFrame()    \n",
    "    \n",
    "    # apply unit-func to each doc & loop over all docs\n",
    "    for i1 in range(len(corpus0)):\n",
    "        doc0 = str(corpus0.iloc[i1])\n",
    "        vs_doc_df = vader_unit_func(doc0,column_name)  # applying unit-func\n",
    "        vs_doc_df.insert(0, 'doc_index', i1)  # inserting doc index\n",
    "        vs_df = pd.concat([vs_df, vs_doc_df], axis=0)\n",
    "        \n",
    "    return(vs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>neg_review</th>\n",
       "      <th>neu_review</th>\n",
       "      <th>pos_review</th>\n",
       "      <th>compound_review</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>neg_title</th>\n",
       "      <th>neu_title</th>\n",
       "      <th>pos_title</th>\n",
       "      <th>compound_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>29-12-2020 01:14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.876</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free offer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>01-01-2021 23:17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>15-01-2021 23:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>08-12-2020 01:01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.167</td>\n",
       "      <td>3.592</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.1617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>15-12-2020 04:02</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>5.614</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.4906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating  \\\n",
       "0        Dishonest and Disgusting     1.0   \n",
       "1                      Free offer     2.0   \n",
       "2                      Inaccurate     2.0   \n",
       "3                             bad     1.0   \n",
       "4  Double charged me for an order     1.0   \n",
       "\n",
       "                                              Review              Date  \\\n",
       "0  For half an hour, we tried EVERY UBER SERVICE ...  29-12-2020 01:14   \n",
       "1  If I’m not eligible for the offer Stop floodin...  01-01-2021 23:17   \n",
       "2  Consistently inaccurate Uber Eats ETA and the ...  15-01-2021 23:38   \n",
       "3  i had my rides canceled back to back. they the...  08-12-2020 01:01   \n",
       "4  Two of the same orders was added by accident. ...  15-12-2020 04:02   \n",
       "\n",
       "   sent_index  neg_review  neu_review  pos_review  compound_review  \\\n",
       "0         3.0       0.000       2.876       0.124           0.1406   \n",
       "1         0.0       0.136       0.864       0.000          -0.2960   \n",
       "2         0.0       0.179       0.821       0.000          -0.3400   \n",
       "3        10.0       1.167       3.592       0.241          -0.1617   \n",
       "4        21.0       0.908       5.614       0.478          -0.4906   \n",
       "\n",
       "   sent_index  neg_title  neu_title  pos_title  compound_title  \n",
       "0         0.0      0.877      0.123      0.000         -0.7964  \n",
       "1         0.0      0.000      0.233      0.767          0.5106  \n",
       "2         0.0      0.000      1.000      0.000          0.0000  \n",
       "3         0.0      1.000      0.000      0.000         -0.5423  \n",
       "4         0.0      0.265      0.735      0.000         -0.2023  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test-drive wrapper func\n",
    "review_sentiment = vader_wrap_func(df1.Review,'_review').groupby('doc_index').sum()\n",
    "title_sentiment = vader_wrap_func(df1.Title,'_title').groupby('doc_index').sum()\n",
    "df1 = pd.concat([df1,review_sentiment,title_sentiment],axis=1)\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29-12-2020 01:14\n",
       "1    01-01-2021 23:17\n",
       "2    15-01-2021 23:38\n",
       "3    08-12-2020 01:01\n",
       "4    15-12-2020 04:02\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-12-29 01:14:00\n",
       "1   2021-01-01 23:17:00\n",
       "2   2021-01-15 23:38:00\n",
       "3   2020-12-08 01:01:00\n",
       "4   2020-12-15 04:02:00\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Date into datetime format\n",
    "df1['Date'] =  pd.to_datetime(df1['Date'], format='%d-%m-%Y %H:%M')\n",
    "df1.Date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>neg_review</th>\n",
       "      <th>neu_review</th>\n",
       "      <th>pos_review</th>\n",
       "      <th>compound_review</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>...</th>\n",
       "      <th>neu_title</th>\n",
       "      <th>pos_title</th>\n",
       "      <th>compound_title</th>\n",
       "      <th>Isweekend</th>\n",
       "      <th>Late_night</th>\n",
       "      <th>Early_mrng</th>\n",
       "      <th>Morning</th>\n",
       "      <th>Noon</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dishonest and Disgusting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>For half an hour, we tried EVERY UBER SERVICE ...</td>\n",
       "      <td>2020-12-29 01:14:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.876</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free offer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>If I’m not eligible for the offer Stop floodin...</td>\n",
       "      <td>2021-01-01 23:17:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaccurate</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Consistently inaccurate Uber Eats ETA and the ...</td>\n",
       "      <td>2021-01-15 23:38:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had my rides canceled back to back. they the...</td>\n",
       "      <td>2020-12-08 01:01:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.167</td>\n",
       "      <td>3.592</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.1617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Double charged me for an order</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Two of the same orders was added by accident. ...</td>\n",
       "      <td>2020-12-15 04:02:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>5.614</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.4906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating  \\\n",
       "0        Dishonest and Disgusting     1.0   \n",
       "1                      Free offer     2.0   \n",
       "2                      Inaccurate     2.0   \n",
       "3                             bad     1.0   \n",
       "4  Double charged me for an order     1.0   \n",
       "\n",
       "                                              Review                Date  \\\n",
       "0  For half an hour, we tried EVERY UBER SERVICE ... 2020-12-29 01:14:00   \n",
       "1  If I’m not eligible for the offer Stop floodin... 2021-01-01 23:17:00   \n",
       "2  Consistently inaccurate Uber Eats ETA and the ... 2021-01-15 23:38:00   \n",
       "3  i had my rides canceled back to back. they the... 2020-12-08 01:01:00   \n",
       "4  Two of the same orders was added by accident. ... 2020-12-15 04:02:00   \n",
       "\n",
       "   sent_index  neg_review  neu_review  pos_review  compound_review  \\\n",
       "0         3.0       0.000       2.876       0.124           0.1406   \n",
       "1         0.0       0.136       0.864       0.000          -0.2960   \n",
       "2         0.0       0.179       0.821       0.000          -0.3400   \n",
       "3        10.0       1.167       3.592       0.241          -0.1617   \n",
       "4        21.0       0.908       5.614       0.478          -0.4906   \n",
       "\n",
       "   sent_index  ...  neu_title  pos_title  compound_title  Isweekend  \\\n",
       "0         0.0  ...      0.123      0.000         -0.7964          0   \n",
       "1         0.0  ...      0.233      0.767          0.5106          0   \n",
       "2         0.0  ...      1.000      0.000          0.0000          0   \n",
       "3         0.0  ...      0.000      0.000         -0.5423          0   \n",
       "4         0.0  ...      0.735      0.000         -0.2023          0   \n",
       "\n",
       "   Late_night  Early_mrng  Morning  Noon  Eve  Night  \n",
       "0           1           0        0     0    0      0  \n",
       "1           0           0        0     0    0      1  \n",
       "2           0           0        0     0    0      1  \n",
       "3           1           0        0     0    0      0  \n",
       "4           0           1        0     0    0      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Isweekend'] = np.where(df1.Date.dt.dayofweek>4,1,0)\n",
    "df1['Late_night'] = np.where(df1.Date.dt.hour<4,1,0)\n",
    "df1['Early_mrng'] = np.where(df1.Date.dt.hour.between(4,8),1,0)\n",
    "df1['Morning'] = np.where(df1.Date.dt.hour.between(8,12),1,0)\n",
    "df1['Noon'] = np.where(df1.Date.dt.hour.between(12,16),1,0)\n",
    "df1['Eve'] = np.where(df1.Date.dt.hour.between(16,20),1,0)\n",
    "df1['Night'] = np.where(df1.Date.dt.hour>20,1,0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>neg_review</th>\n",
       "      <th>neu_review</th>\n",
       "      <th>pos_review</th>\n",
       "      <th>compound_review</th>\n",
       "      <th>neg_title</th>\n",
       "      <th>neu_title</th>\n",
       "      <th>pos_title</th>\n",
       "      <th>compound_title</th>\n",
       "      <th>Isweekend</th>\n",
       "      <th>Late_night</th>\n",
       "      <th>Early_mrng</th>\n",
       "      <th>Morning</th>\n",
       "      <th>Noon</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.876</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.167</td>\n",
       "      <td>3.592</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.1617</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>5.614</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-0.4906</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  neg_review  neu_review  pos_review  compound_review  neg_title  \\\n",
       "0     1.0       0.000       2.876       0.124           0.1406      0.877   \n",
       "1     2.0       0.136       0.864       0.000          -0.2960      0.000   \n",
       "2     2.0       0.179       0.821       0.000          -0.3400      0.000   \n",
       "3     1.0       1.167       3.592       0.241          -0.1617      1.000   \n",
       "4     1.0       0.908       5.614       0.478          -0.4906      0.265   \n",
       "\n",
       "   neu_title  pos_title  compound_title  Isweekend  Late_night  Early_mrng  \\\n",
       "0      0.123      0.000         -0.7964          0           1           0   \n",
       "1      0.233      0.767          0.5106          0           0           0   \n",
       "2      1.000      0.000          0.0000          0           0           0   \n",
       "3      0.000      0.000         -0.5423          0           1           0   \n",
       "4      0.735      0.000         -0.2023          0           0           1   \n",
       "\n",
       "   Morning  Noon  Eve  Night  \n",
       "0        0     0    0      0  \n",
       "1        0     0    0      1  \n",
       "2        0     0    0      1  \n",
       "3        0     0    0      0  \n",
       "4        0     0    0      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.drop(['sent_index','Title','Review','Date'],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((490,), (490, 15))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1.Rating\n",
    "X = df1.drop('Rating', axis=1)\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const              0\n",
       "neg_review         1\n",
       "neu_review         1\n",
       "pos_review         1\n",
       "compound_review    1\n",
       "neg_title          1\n",
       "neu_title          1\n",
       "pos_title          1\n",
       "compound_title     1\n",
       "Isweekend          0\n",
       "Late_night         0\n",
       "Early_mrng         0\n",
       "Morning            0\n",
       "Noon               0\n",
       "Eve                0\n",
       "Night              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5eea1e159653>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    870\u001b[0m     def __init__(self, endog, exog=None, missing='none', hasconst=None,\n\u001b[0;32m    871\u001b[0m                  **kwargs):\n\u001b[1;32m--> 872\u001b[1;33m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    873\u001b[0m                                   hasconst=hasconst, **kwargs)\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    704\u001b[0m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0;32m    705\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'missing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[0;32m     78\u001b[0m                                       **kwargs)\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[0;32m    673\u001b[0m                  **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mexog_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mMissingDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exog contains inf or nans'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[0mexog_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mconst_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog_max\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexog_min\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "1. Convert non-English reviews to English or use non-english dictionary\n",
    "2. Scale the emoticons replacement\n",
    "3. Make sentiment analysis of Title - Done\n",
    "4. From Date, extract weekend, weekday, morning, afternoon, evening, night - Done\n",
    "5. Make preliminary regression model with y variable as Ratings\n",
    "6. ?Use OLS\n",
    "7. Feature Engineering - columns on specific word count\n",
    "8. Shiny App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
